{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6141ec4-c5c7-42ae-acb7-e89b6f9161a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           file_name                                               text  \\\n",
      "0      badminton.txt  Badminton is a racquet sport played using racq...   \n",
      "1   barack obama.txt  Barack Hussein Obama II (born August 4, 1961) ...   \n",
      "2       baseball.txt  Baseball is a bat-and-ball game played between...   \n",
      "3   lee quan yew.txt  Lee Kuan Yew, GCMG, CH, SPMJ (born Harry Lee K...   \n",
      "4  narendra modi.txt  Narendra Damodardas Modi (born 17 September 19...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  badminton racquet sport play use racquet hit s...  \n",
      "1  barack hussein obama ii ( born august 4 , 1961...  \n",
      "2  basebal bat-and-bal game play two team nine pl...  \n",
      "3  lee kuan yew , gcmg , ch , spmj ( born harri l...  \n",
      "4  narendra damodarda modi ( born 17 septemb 1950...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarwa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Path to the folder containing text files\n",
    "folder_path = 'data'\n",
    "\n",
    "# Initialize lists to store file names and text data\n",
    "file_names = []\n",
    "text_data = []\n",
    "\n",
    "# Read all text files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "            file_names.append(file_name)\n",
    "            text_data.append(file.read())\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'file_name': file_names, 'text': text_data})\n",
    "\n",
    "# Preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [ps.stem(word) for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['processed_text'] = data['text'].apply(preprocess)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932fd344-d720-4287-8322-eea88c0d42d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.0019422  0.13301019 0.0242031  0.0279295  0.01378345\n",
      "  0.00588617 0.23820629]\n",
      " [0.0019422  1.         0.04499789 0.10135787 0.05576688 0.02060439\n",
      "  0.08394575 0.01821279]\n",
      " [0.13301019 0.04499789 1.         0.021111   0.02106339 0.01497158\n",
      "  0.02474223 0.09300259]\n",
      " [0.0242031  0.10135787 0.021111   1.         0.10885693 0.0310234\n",
      "  0.11210892 0.05343237]\n",
      " [0.0279295  0.05576688 0.02106339 0.10885693 1.         0.02281268\n",
      "  0.17992368 0.03642488]\n",
      " [0.01378345 0.02060439 0.01497158 0.0310234  0.02281268 1.\n",
      "  0.03316937 0.02457381]\n",
      " [0.00588617 0.08394575 0.02474223 0.11210892 0.17992368 0.03316937\n",
      "  1.         0.0157528 ]\n",
      " [0.23820629 0.01821279 0.09300259 0.05343237 0.03642488 0.02457381\n",
      "  0.0157528  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba7952b-6eca-4edb-93f1-48135ba75cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.0019422  0.13301019 0.0242031  0.0279295  0.01378345\n",
      "  0.00588617 0.23820629]\n",
      " [0.0019422  1.         0.04499789 0.10135787 0.05576688 0.02060439\n",
      "  0.08394575 0.01821279]\n",
      " [0.13301019 0.04499789 1.         0.021111   0.02106339 0.01497158\n",
      "  0.02474223 0.09300259]\n",
      " [0.0242031  0.10135787 0.021111   1.         0.10885693 0.0310234\n",
      "  0.11210892 0.05343237]\n",
      " [0.0279295  0.05576688 0.02106339 0.10885693 1.         0.02281268\n",
      "  0.17992368 0.03642488]\n",
      " [0.01378345 0.02060439 0.01497158 0.0310234  0.02281268 1.\n",
      "  0.03316937 0.02457381]\n",
      " [0.00588617 0.08394575 0.02474223 0.11210892 0.17992368 0.03316937\n",
      "  1.         0.0157528 ]\n",
      " [0.23820629 0.01821279 0.09300259 0.05343237 0.03642488 0.02457381\n",
      "  0.0157528  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply LSA\n",
    "lsa = TruncatedSVD(n_components=100)\n",
    "lsa_matrix = lsa.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Calculate Cosine Similarity in LSA space\n",
    "lsa_similarity_matrix = cosine_similarity(lsa_matrix)\n",
    "print(lsa_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "729363a1-3b16-4ddd-9307-6a518cda9df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             file_name  cluster\n",
      "0        badminton.txt        2\n",
      "1     barack obama.txt        4\n",
      "2         baseball.txt        1\n",
      "3     lee quan yew.txt        4\n",
      "4    narendra modi.txt        0\n",
      "5  queen elizabeth.txt        3\n",
      "6       shinzo abe.txt        0\n",
      "7     table tennis.txt        2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = 5\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "data['cluster'] = kmeans.labels_\n",
    "print(data[['file_name', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd52f1d-30bb-45f3-8555-5018ede29324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
